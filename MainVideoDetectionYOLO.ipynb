{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNDdvnulRnvo0N24sQOSKVR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jotramon/MillAI/blob/main/MainVideoDetectionYOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: clear results\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "30YKvh6lBEqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "# clear_output()"
      ],
      "metadata": {
        "id": "-jc7L9sgAr9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e677709-ac18-4bba-dec9-eff9b1d4792c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.9)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.plotting import Annotator, colors\n",
        "\n",
        "logging.basicConfig(\n",
        "    filename='object_detection.log',\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiwBGU6xAJK-",
        "outputId": "bfd2c4ae-91e0-474c-f076-7be7d8842e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set YOLOv8 to quiet mode\n",
        "os.environ['YOLO_VERBOSE'] = 'False'"
      ],
      "metadata": {
        "id": "anP1h5OjyFkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABrUkZ_GAOR4",
        "outputId": "1d25a5f4-b48c-40f0-96de-5018d2a6ec58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clases para la detección en videovigilancia"
      ],
      "metadata": {
        "id": "rohTQKT7DJEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ObjectDetection:\n",
        "    def __init__(self, capture_index=None, output_video_path='output.avi'):\n",
        "        \"\"\"Initializes an ObjectDetection instance with a given camera index and output video path.\"\"\"\n",
        "        self.capture_index = capture_index\n",
        "        self.output_video_path = output_video_path\n",
        "        self.email_sent = False\n",
        "\n",
        "        # model information\n",
        "        self.model = YOLO(\"yolo11n.pt\",verbose=False)\n",
        "\n",
        "        # visual information\n",
        "        self.annotator = None\n",
        "        self.start_time = 0\n",
        "        self.end_time = 0\n",
        "\n",
        "        # device information\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        # VideoWriter for saving the output video\n",
        "        self.output_writer = None\n",
        "\n",
        "    def predict(self, im0):\n",
        "        \"\"\"Run prediction using a YOLO model for the input image `im0`.\"\"\"\n",
        "        results = self.model(im0,verbose=False)\n",
        "        return results\n",
        "\n",
        "    def display_fps(self, im0):\n",
        "        \"\"\"Displays the FPS on an image `im0`.\"\"\"\n",
        "        self.end_time = time()\n",
        "        fps = 1 / round(self.end_time - self.start_time, 2)\n",
        "        text = f\"FPS: {int(fps)}\"\n",
        "        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)[0]\n",
        "        gap = 10\n",
        "        cv2.rectangle(\n",
        "            im0,\n",
        "            (20 - gap, 70 - text_size[1] - gap),\n",
        "            (20 + text_size[0] + gap, 70 + gap),\n",
        "            (255, 255, 255),\n",
        "            -1,\n",
        "        )\n",
        "        cv2.putText(im0, text, (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 2)\n",
        "\n",
        "    def plot_bboxes(self, results, im0):\n",
        "        \"\"\"Plots bounding boxes on an image given detection results.\"\"\"\n",
        "        class_ids = []\n",
        "        self.annotator = Annotator(im0, 3, results[0].names)\n",
        "        boxes = results[0].boxes.xyxy.cpu()\n",
        "        clss = results[0].boxes.cls.cpu().tolist()\n",
        "        names = results[0].names\n",
        "        for box, cls in zip(boxes, clss):\n",
        "            class_ids.append(cls)\n",
        "            self.annotator.box_label(box, label=names[int(cls)], color=colors(int(cls), True))\n",
        "        return im0, class_ids\n",
        "\n",
        "    def __call__(self, video_path=None):\n",
        "        \"\"\"Run object detection on video frames from a camera stream, plotting and showing the results.\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path or self.capture_index)\n",
        "        # self.output_video_path = video_path.split('.')[0] + '_output.mp4'\n",
        "        assert cap.isOpened()\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "        # Initialize VideoWriter\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS) # Set this according to your video\n",
        "        self.output_writer = cv2.VideoWriter(self.output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "        frame_count = 0\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        with tqdm(total=total_frames, desc='Processing frames') as pbar:\n",
        "          while True:\n",
        "              self.start_time = time()\n",
        "              ret, im0 = cap.read()\n",
        "              if not ret:\n",
        "                  break\n",
        "\n",
        "              results = self.predict(im0)\n",
        "              im0, class_ids = self.plot_bboxes(results, im0)\n",
        "\n",
        "              self.display_fps(im0)\n",
        "\n",
        "              logging.info(f'Detected objects: {len(class_ids)}')\n",
        "              # cv2.imshow(\"YOLO11 Detection\", im0)\n",
        "\n",
        "              # Write the frame to the output video\n",
        "              self.output_writer.write(im0)\n",
        "              pbar.update(1)\n",
        "              frame_count += 1\n",
        "              if cv2.waitKey(5) & 0xFF == 27:  # Press 'Esc' to exit\n",
        "                  break\n",
        "              # if frame_count == 5000:\n",
        "              #   break\n",
        "\n",
        "        cap.release()\n",
        "        self.output_writer.release()  # Release the VideoWriter\n",
        "        cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "eLLOfkHsuAmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = ObjectDetection(\"\",output_video_path=\"\")\n",
        "detector()"
      ],
      "metadata": {
        "id": "4pZ8Eh9ZDYM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Método sencillo de inferencia para la detección de objetos"
      ],
      "metadata": {
        "id": "MVJXMqLODQrz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dpuwtq48pk6Q"
      },
      "outputs": [],
      "source": [
        "# Load a model\n",
        "model = YOLO(\"yolo11n.pt\")  # pretrained YOLO11n model\n",
        "\n",
        "# Run batched inference on a list of images\n",
        "results = model([\"image1.jpg\", \"image2.jpg\"], stream=True)  # return a generator of Results objects\n",
        "\n",
        "# Process results generator\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
        "    result.show()  # display to screen\n",
        "    result.save(filename=\"result.jpg\")  # save to disk"
      ]
    }
  ]
}